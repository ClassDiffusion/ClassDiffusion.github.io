<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
    <!-- Replace the content tag with appropriate information -->
    <meta name="description" content="DESCRIPTION META TAG" />
    <meta property="og:title" content="SOCIAL MEDIA TITLE TAG" />
    <meta
      property="og:description"
      content="SOCIAL MEDIA DESCRIPTION TAG TAG"
    />
    <meta property="og:url" content="URL OF THE WEBSITE" />
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
    <meta property="og:image" content="static/image/your_banner_image.png" />
    <meta property="og:image:width" content="1200" />
    <meta property="og:image:height" content="630" />

    <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG" />
    <meta
      name="twitter:description"
      content="TWITTER BANNER DESCRIPTION META TAG"
    />
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
    <meta
      name="twitter:image"
      content="static/images/your_twitter_banner_image.png"
    />
    <meta name="twitter:card" content="summary_large_image" />
    <!-- Keywords for your paper to be indexed by-->
    <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>
      ClassDiffusion
    </title>
    <link rel="icon" type="image/x-icon" href="static/images/favicon.ico" />
    <link
      href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
      rel="stylesheet"
    />

    <link rel="stylesheet" href="static/css/bulma.min.css" />
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css" />
    <link rel="stylesheet" href="static/css/bulma-slider.min.css" />
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css" />
    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css"
    />
    <link rel="stylesheet" href="static/css/index.css" />

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
    <script defer src="static/js/fontawesome.all.min.js"></script>
    <script src="static/js/bulma-carousel.min.js"></script>
    <script src="static/js/bulma-slider.min.js"></script>
    <script src="static/js/index.js"></script>
  </head>
  <body>
    <section class="hero">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <div class="columns is-centered">
            <div class="column has-text-centered">
              <h1 class="title is-1 publication-title">
                ClassDiffusion: More Aligned Personalization Tuning with Explicit Class Guidance
              </h1>
              <div class="is-size-5 publication-authors">
                <!-- Paper authors -->
                <span class="author-block">
                  <a href="https://rbrq03.github.io/" target="_blank"
                    >Jiannan Huang</a
                  ><sup>1</sup>,</span
                >
                <span class="author-block">
                  <a href="https://scholar.google.com.sg/citations?user=8gm-CYYAAAAJ" target="_blank"
                    >Jun Hao Liew</a
                  ><sup>2</sup>,</span
                >
                <span class="author-block">
                  <a href="https://hanshuyan.github.io/" target="_blank"
                    >Hanshu Yan</a
                  ><sup>2</sup>,</span
                >
                <span class="author-block">
                  <a href="https://yuyangyin.github.io/" target="_blank"
                    >Yuyang Yin</a
                  ><sup>1</sup>,</span
                >
                <span class="author-block">
                  <a href="http://mepro.bjtu.edu.cn/zhaoyao/index.htm" target="_blank"
                    >Yao Zhao</a
                  ><sup>1</sup>,</span
                >
                <span class="author-block">
                  <a href="https://weiyc.github.io/index.html" target="_blank"
                    >Yunchao Wei</a
                  ><sup>1</sup>,</span
                >
                </span>
              </div>

              <div class="is-size-5 publication-authors">
                <span class="author-block"
                  ><sup>1</sup>Beijing Jiaotong University<br /><sup>2</sup>ByteDance Inc.</span
                >
              </div>

              <div class="column has-text-centered">
                <div class="publication-links">
                  <!-- Arxiv PDF link -->
                  <span class="link-block">
                    <a
                      href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf"
                      target="_blank"
                      class="external-link button is-normal is-rounded is-dark"
                    >
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Paper - Coming Soon</span>
                    </a>
                  </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a
                      href="https://github.com/Rbrq03/ClassDiffusion"
                      target="_blank"
                      class="external-link button is-normal is-rounded is-dark"
                    >
                      <span class="icon">
                        <i class="fab fa-github"></i>
                      </span>
                      <span>Code - Coming Soon</span>
                    </a>
                  </span>

                  <!-- ArXiv abstract Link -->
                  <span class="link-block">
                    <a
                      href="https://arxiv.org/abs/<ARXIV PAPER ID>"
                      target="_blank"
                      class="external-link button is-normal is-rounded is-dark"
                    >
                      <span class="icon">
                        <i class="ai ai-arxiv"></i>
                      </span>
                      <span>arXiv - Coming Soon</span>
                    </a>
                  </span>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- Teaser image-->
    <section class="hero teaser">
      <div class="container is-max-desktop">
        <div class="hero-body">
          <img src="static/images/story_page-0001.jpg" alt="teaser image" />
          <h2 class="subtitle has-text-centered">
            Stroy of given dog and sunglasses, showing how a dog win the Nobel prize for literature, and the fate of a sunglasses.
          </h2>
        </div>
      </div>
    </section>
    <!-- End teaser video -->

    <!-- Paper abstract -->
    <section class="section hero is-light">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Abstract</h2>
            <div class="content has-text-justified">
              <p>
                Recent text-to-image customization works have been proven successful in generating images of given concepts by fine-tuning the diffusion models on a few examples. However, these methods tend to overfit the concepts, resulting in failure to create the concept under multiple conditions (<i>e.g.</i> headphone is missing when generating a dog wearing a headphone'). Interestingly, we notice that the base model before fine-tuning exhibits the capability to compose the base concept with other elements (<i>e.g.</i> a dog wearing a headphone) implying that the compositional ability only disappears after personalization tuning. Inspired by this observation, we present ClassDiffusion, a simple technique that leverages a semantic preservation loss to explicitly regulate the concept space when learning the new concept. Despite its simplicity, this helps avoid semantic drift when fine-tuning on the target concepts. Extensive qualitative and quantitative experiments demonstrate that the use of semantic preservation loss effectively improves the compositional abilities of the fine-tune models. In response to the ineffective evaluation of CLIP-T metrics, we introduce BLIP2-T metric, a more equitable and effective evaluation metric for this particular domain. We also provide in-depth empirical study and theoretical analysis to better understand the role of the proposed loss. Lastly, we also extend our ClassDiffusion to personalized video generation, demonstrating its flexibility.
              </p>
            </div>
          </div>
        </div>
      </div>
    </section>
    <!-- End paper abstract -->

    <!-- <section class="hero teaser">
      <div class="container is-max-desktop">
        <div class="hero-body">
          <img src="static/images/method_new_page-0001.jpg" alt="teaser image" />
          <h2 class="subtitle has-text-centered">
            Overview of our proposed ClassDiffusion. Our semantic preservation loss (SPL) is calculated by measuring the cosine distance between text features extracted from the same text transformer (using EOS tokens as text features following CLIP) for phrases with personalized tokens and phrases with only superclasses.
          </h2>
        </div>
      </div>
    </section> -->

    <!-- Image carousel -->
    <!-- <section class="hero is-small">
      <div class="hero-body">
        <div class="container"> 
          <h2 class="title is-3">Single Concept Personalization</h2>
          <div id="results-carousel" class="carousel results-carousel">
            <div class="item">
              <img src="static/images/carousel1.jpg" alt="MY ALT TEXT" />
              <h2 class="subtitle has-text-centered">
                First image description.
              </h2>
            </div>
            <div class="item">
              <img src="static/images/method_new_page-0001.jpg" alt="MY ALT TEXT" />
              <h2 class="subtitle has-text-centered">
                Overview of our proposed ClassDiffusion. Our semantic preservation loss (SPL) is calculated by measuring the cosine distance between text features extracted from the same text transformer (using EOS tokens as text features following CLIP) for phrases with personalized tokens and phrases with only superclasses.
              </h2>
            </div>
            <div class="item">
              <img src="static/images/carousel3.jpg" alt="MY ALT TEXT" />
              <h2 class="subtitle has-text-centered">
                Third image description.
              </h2>
            </div>
            <div class="item">
              <img src="static/images/carousel4.jpg" alt="MY ALT TEXT" />
              <h2 class="subtitle has-text-centered">
                Fourth image description.
              </h2>
            </div>
          </div>
        </div>
      </div>
    </section> -->
    <!-- End image carousel -->

    <section class="section is-small">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column is-full">
            <div class="content">
              <h2 class="title is-3">Single Concept Comparison</h2>
              <center>
              <img src="static/images/singleconcept.png" alt="Inference Overview" class="center-image">
              </center>
              <div class="level-set has-text-justified">
                <p>
                  Qualitative comparison between our method and baselines with single given concept.
                </p>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <section class="section is-small">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column is-full">
            <div class="content">
              <h2 class="title is-3">Multiple Concepts Comparison</h2>
              <center>
              <img src="static/images/multiple.png" alt="Inference Overview" class="center-image">
              </center>
              <div class="level-set has-text-justified">
                <p>
                  Qualitative comparison between our method and custom diffusion(CD) with multiple given concept.
                </p>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>


    <section class="section is-small">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column is-full">
            <div class="content">
              <h2 class="title is-3">Personalized Video</h2>
              <div id="results-carousel" class="carousel results-carousel">
                <div class="item">
                  <div class="media-container">
                    <img src="static/images/dog.jpeg" alt="MY ALT TEXT" />
                    <video autoplay loop muted>
                      <source src="static/images/dog.mp4" type="video/mp4">
                    </video>
                  </div>
                  <p class="subtitle has-text-centered">
                    A dog running on the street.
                  </p>
                </div>
                <div class="item">
                  <div class="media-container">
                    <img src="static/images/duck_toy.jpg" alt="MY ALT TEXT" />
                    <video autoplay loop muted>
                      <source src="static/images/duck_toy.mp4" type="video/mp4">
                    </video>
                  </div>
                  <p class="subtitle has-text-centered">
                    A duck toy floating on the water.
                  </p>
                </div>
                <div class="item">
                  <div class="media-container">
                    <img src="static/images/cat.jpg" alt="MY ALT TEXT" />
                    <video autoplay loop muted>
                      <source src="static/images/cat.mp4" type="video/mp4">
                    </video>
                  </div>
                  <p class="subtitle has-text-centered">
                    A cat chasing a ball.
                  </p>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>
    
    <style>
      .media-container {
        display: flex;
        justify-content: space-between;
        align-items: center;
        margin-bottom: 1rem;
      }
    
      .media-container img, .media-container video {
        width: 48%;
        height: auto;
      }
    
      .subtitle.has-text-centered {
        margin-top: 0.5rem;
        font-family: 'Comic Sans MS', 'Comic Sans', cursive, sans-serif;
      }
    </style>
    

    <!-- <section class="section is-small">
      <div class="hero-body">
        <div class="container"> 
          <h2 class="title is-3">Analysis</h2>
          <div id="results-carousel" class="carousel results-carousel">
            <div class="item">
              <img src="static/images/exp_ob.png" alt="MY ALT TEXT" />
              <h2 class="subtitle has-text-centered">
                (a) Each dot represents the CLIP text embedding of a phrase combining an adjective and &quot; dog &quot; (<i>e.g.</i>, a cute dog). After fine-tuning, customized concepts (the blue dot represents the concept before fine-tuning, and the red dot represents the one after) become far away from the center of the &quot;dog&quot; distribution in the text feature space. (b) Visualization results of cross-attention maps corresponding to the dog token when using the prompt &quot;a photo of a dog swimming in the pool &quot;.
              </h2>
            </div>
            <div class="item">
              <img src="static/images/theoretical_page-0001.jpg" alt="MY ALT TEXT" />
              <h2 class="subtitle has-text-centered">
                Overview of our proposed ClassDiffusion. Our semantic preservation loss (SPL) is calculated by measuring the cosine distance between text features extracted from the same text transformer (using EOS tokens as text features following CLIP) for phrases with personalized tokens and phrases with only superclasses.
              </h2>
            </div>
          </div>
        </div>
      </div>
    </section> -->

    <section class="section is-small">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column is-full">
            <div class="content">
              <h2 class="title is-3">Emperical Analysis</h2>
              <center>
              <img src="static/images/exp_ob.png" alt="Inference Overview" class="center-image">
              </center>
              <div class="level-set has-text-justified">
                <p>
                  (a) Each dot represents the CLIP text embedding of a phrase combining an adjective and &quot; dog &quot; (<i>e.g.</i>, a cute dog). After fine-tuning, customized concepts (the blue dot represents the concept before fine-tuning, and the red dot represents the one after) become far away from the center of the &quot;dog&quot; distribution in the text feature space. (b) Visualization results of cross-attention maps corresponding to the dog token when using the prompt &quot;a photo of a dog swimming in the pool &quot;.
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <section class="section is-small">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column is-full">
            <div class="content">
              <h2 class="title is-3">Theoretical Analysis</h2>
              <center>
              <img src="static/images/theoretical_page-0001.jpg" alt="Inference Overview" class="center-image">
              </center>
              <div class="level-set has-text-justified">
                <p>
                  During the personalization tuning process, as the distribution of dogs shrinks, the conditional distribution of dogs and headphones also shrinks. This gradually increases the difficulty to sample in this distribution, leading to the weakening of the compositional generation capability. Our ClassDiffusion mitigates this by incorporating semantic preservation loss (SPL) to minimize the semantic drift of the personalized concept from its superclass.
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <section class="section is-small">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column is-full">
            <div class="content">
              <h2 class="title is-3">Method Overview</h2>
              <center>
              <img src="static/images/method_new_page-0001.jpg" alt="Inference Overview" class="center-image">
              </center>
              <div class="level-set has-text-justified">
                <p>
                  Overview of our proposed ClassDiffusion. Our semantic preservation loss (SPL) is calculated by measuring the cosine distance between text features extracted from the same text transformer (using EOS tokens as text features following CLIP) for phrases with personalized tokens and phrases with only superclasses.
                </p>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- Youtube video -->
    <!-- <section class="hero is-small is-light">
      <div class="hero-body">
        <div class="container"> -->
          <!-- Paper video. -->
          <!-- <h2 class="title is-3">Video Presentation</h2>
          <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
              <div class="publication-video"> -->
                <!-- Youtube embed code here -->
                <!-- <iframe
                  src="https://www.youtube.com/embed/JkaxUblCGz0"
                  frameborder="0"
                  allow="autoplay; encrypted-media"
                  allowfullscreen
                ></iframe>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section> -->
    <!-- End youtube video -->

    <!-- Video carousel -->
    <!-- <section class="hero is-small">
      <div class="hero-body">
        <div class="container">
          <h2 class="title is-3">Another Carousel</h2>
          <div id="results-carousel" class="carousel results-carousel">
            <div class="item item-video1">
              <video
                poster=""
                id="video1"
                autoplay
                controls
                muted
                loop
                height="100%"
              > -->
                <!-- Your video file here -->
                <!-- <source src="static/videos/carousel1.mp4" type="video/mp4" />
              </video>
            </div>
            <div class="item item-video2">
              <video
                poster=""
                id="video2"
                autoplay
                controls
                muted
                loop
                height="100%"
              > -->
                <!-- Your video file here -->
                <!-- <source src="static/videos/carousel2.mp4" type="video/mp4" />
              </video>
            </div>
            <div class="item item-video3">
              <video
                poster=""
                id="video3"
                autoplay
                controls
                muted
                loop
                height="100%"
              >
                \ -->
                <!-- Your video file here -->
                <!-- <source src="static/videos/carousel3.mp4" type="video/mp4" />
              </video>
            </div>
          </div>
        </div>
      </div>
    </section> -->
    <!-- End video carousel -->

    <!-- Paper poster -->
    <!-- <section class="hero is-small is-light">
      <div class="hero-body">
        <div class="container">
          <h2 class="title">Poster</h2>

          <iframe src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        </div>
      </div>
    </section> -->
    <!--End paper poster -->

    <!--BibTex citation -->
    <section class="section" id="BibTeX">
      <div class="container is-max-desktop content">
        <h2 class="title">BibTeX</h2>
        <pre><code>BibTex Code Here</code></pre>
      </div>
    </section>
    <!--End BibTex citation -->

    <footer class="footer">
      <div class="container">
        <div class="columns is-centered">
          <div class="column is-8">
            <div class="content">
              <p>
                This page was built using the
                <a
                  href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                  target="_blank"
                  >Academic Project Page Template</a
                >
                which was adopted from the <a
                  href="https://nerfies.github.io"
                  target="_blank"
                  >Nerfies</a
                > project page. You are free to borrow the of this website, we
                just ask that you link back to this page in the footer. <br />
                This website is licensed under a
                <a
                  rel="license"
                  href="http://creativecommons.org/licenses/by-sa/4.0/"
                  target="_blank"
                  >Creative Commons Attribution-ShareAlike 4.0 International
                  License</a
                >.
              </p>
            </div>
          </div>
        </div>
      </div>
    </footer>

    <!-- Statcounter tracking code -->

    <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->
  </body>
</html>
